#!/usr/bin/env python3
"""
Real OpenAI Application Test
This is an unmodified OpenAI application that should work transparently
with the interceptor without any code changes.
"""

import os
from openai import OpenAI

def main():
    """Test a real OpenAI application without modifications."""
    print("ğŸ§ª Testing Real OpenAI Application (Unmodified)")
    print("=" * 50)
    
    # This is exactly how a real application would use OpenAI
    # NO base_url modification, NO special configuration
    client = OpenAI(
        api_key="dummy-key-for-testing-interceptor"  # Dummy key - should still work with interceptor
    )
    
    print("âœ… OpenAI client initialized (standard way)")
    print(f"ğŸ“ Client will connect to: {client.base_url}")
    print()
    
    try:
        print("ğŸš€ Making OpenAI API call...")
        print("   (This should be intercepted and routed to Codegen SDK)")
        print()
        
        # Standard OpenAI API call - exactly as any app would do it
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system", 
                    "content": "You are a helpful assistant. Respond briefly."
                },
                {
                    "role": "user", 
                    "content": "Hello! This is a test of transparent OpenAI API interception. Please confirm you received this message."
                }
            ],
            max_tokens=100,
            temperature=0.7
        )
        
        print("ğŸ‰ SUCCESS! OpenAI API call completed successfully!")
        print("âœ… Transparent interception is working!")
        print()
        print("ğŸ“ Response from Codegen SDK:")
        print("-" * 30)
        print(response.choices[0].message.content)
        print("-" * 30)
        print()
        print(f"ğŸ“Š Model used: {response.model}")
        print(f"ğŸ”¢ Tokens used: {response.usage.total_tokens if response.usage else 'N/A'}")
        print()
        print("ğŸ¯ This proves that:")
        print("   âœ… Unmodified OpenAI applications work with interceptor")
        print("   âœ… DNS interception is functioning")
        print("   âœ… API requests are routed to Codegen SDK")
        print("   âœ… Responses are properly formatted")
        
        return True
        
    except Exception as e:
        print(f"âŒ OpenAI API call failed: {e}")
        print()
        print("ğŸ” This could mean:")
        print("   â€¢ Interceptor service is not running")
        print("   â€¢ DNS interception is not configured")
        print("   â€¢ SSL certificates are missing")
        print("   â€¢ Codegen SDK credentials are invalid")
        print()
        print("ğŸ”§ Try:")
        print("   1. sudo systemctl status openai-interceptor")
        print("   2. sudo python3 -m interceptor.ubuntu_dns status")
        print("   3. sudo python3 -m interceptor.ubuntu_ssl status")
        
        return False

def test_multiple_requests():
    """Test multiple API calls to ensure consistency."""
    print("\nğŸ”„ Testing Multiple API Calls")
    print("=" * 30)
    
    client = OpenAI(api_key="dummy-key-for-testing")
    
    test_prompts = [
        "What is 2+2?",
        "Tell me a joke",
        "Explain quantum computing in one sentence"
    ]
    
    for i, prompt in enumerate(test_prompts, 1):
        try:
            print(f"ğŸ“¤ Request {i}: {prompt}")
            
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=50
            )
            
            print(f"ğŸ“¥ Response {i}: {response.choices[0].message.content[:100]}...")
            print()
            
        except Exception as e:
            print(f"âŒ Request {i} failed: {e}")
            return False
    
    print("âœ… All multiple requests succeeded!")
    return True

def test_different_models():
    """Test different model requests."""
    print("\nğŸ¤– Testing Different Models")
    print("=" * 30)
    
    client = OpenAI(api_key="dummy-key-for-testing")
    
    models_to_test = [
        "gpt-3.5-turbo",
        "gpt-4",
        "gpt-4-turbo"
    ]
    
    for model in models_to_test:
        try:
            print(f"ğŸ§  Testing model: {model}")
            
            response = client.chat.completions.create(
                model=model,
                messages=[{"role": "user", "content": f"Hello from {model}!"}],
                max_tokens=30
            )
            
            print(f"âœ… {model}: {response.choices[0].message.content[:50]}...")
            print()
            
        except Exception as e:
            print(f"âŒ {model} failed: {e}")
    
    return True

if __name__ == "__main__":
    print("ğŸ¯ Real OpenAI Application Test")
    print("This application uses OpenAI API exactly as any real app would")
    print("NO modifications, NO special configuration")
    print("If transparent interception works, this will succeed with dummy keys")
    print()
    
    # Test basic functionality
    success = main()
    
    if success:
        # Test additional scenarios
        test_multiple_requests()
        test_different_models()
        
        print("\nğŸ‰ TRANSPARENT INTERCEPTION FULLY VERIFIED!")
        print("âœ… Unmodified OpenAI applications work perfectly")
        print("âœ… All API calls routed to Codegen SDK")
        print("âœ… No code changes required for existing apps")
    else:
        print("\nâŒ Transparent interception needs configuration")
        print("Run: sudo ./install-ubuntu.sh")
