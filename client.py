"""
Unified client for OpenAI, Anthropic, and Google API interactions.
Consolidates all provider-specific functionality into a single, simple interface.
"""

import asyncio
import logging
import time
import json
from typing import Optional, AsyncGenerator, Dict, Any, Union, List
from enum import Enum
from codegen import Agent
from codegen_api_client.exceptions import ApiException
import uuid

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ProviderType(Enum):
    """Supported API providers."""
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    GOOGLE = "google"


class UnifiedClient:
    """
    Unified client that handles all three API providers (OpenAI, Anthropic, Google)
    with a simple, consistent interface.
    """
    
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None):
        """
        Initialize the unified client.
        
        Args:
            api_key: API key for Codegen service
            base_url: Base URL for Codegen service
        """
        self.api_key = api_key
        self.base_url = base_url
        self.agent = None
        self._initialize_agent()
    
    def _initialize_agent(self):
        """Initialize the Codegen agent."""
        try:
            kwargs = {}
            if self.api_key:
                kwargs['token'] = self.api_key  # Changed from 'api_key' to 'token'
            if self.base_url:
                kwargs['base_url'] = self.base_url
            
            # If no token provided, try to get from environment or use a default
            if 'token' not in kwargs:
                import os
                token = os.getenv('CODEGEN_API_KEY') or os.getenv('CODEGEN_TOKEN')
                if token:
                    kwargs['token'] = token
                else:
                    # For testing purposes, use a placeholder token
                    kwargs['token'] = 'test-token'
            
            self.agent = Agent(**kwargs)
            logger.info("Codegen agent initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize Codegen agent: {e}")
            # For testing, create a mock agent
            self.agent = None
            logger.warning("Using mock agent for testing")
    
    async def send_message(self, message: str, provider: ProviderType, model: Optional[str] = None) -> Dict[str, Any]:
        """
        Send a message to the specified provider and get a response.
        
        Args:
            message: The message to send
            provider: Which API provider to use
            model: Optional model specification
            
        Returns:
            Dict containing the response from the provider
        """
        if not self.agent:
            raise RuntimeError("Agent not initialized")
        
        try:
            # Prepare the request based on provider
            if provider == ProviderType.OPENAI:
                return await self._send_openai_message(message, model)
            elif provider == ProviderType.ANTHROPIC:
                return await self._send_anthropic_message(message, model)
            elif provider == ProviderType.GOOGLE:
                return await self._send_google_message(message, model)
            else:
                raise ValueError(f"Unsupported provider: {provider}")
                
        except Exception as e:
            logger.error(f"Error sending message to {provider.value}: {e}")
            raise
    
    async def _send_openai_message(self, message: str, model: Optional[str] = None) -> Dict[str, Any]:
        """Send message using OpenAI format."""
        model = model or "gpt-3.5-turbo"
        
        request_data = {
            "model": model,
            "messages": [{"role": "user", "content": message}],
            "max_tokens": 150,
            "temperature": 0.7
        }
        
        start_time = time.time()
        try:
            response = await self.agent.chat_completions_create(**request_data)
            processing_time = time.time() - start_time
            
            return {
                "provider": "openai",
                "model": model,
                "response": response,
                "processing_time": processing_time,
                "success": True
            }
        except Exception as e:
            processing_time = time.time() - start_time
            return {
                "provider": "openai",
                "model": model,
                "error": str(e),
                "processing_time": processing_time,
                "success": False
            }
    
    async def _send_anthropic_message(self, message: str, model: Optional[str] = None) -> Dict[str, Any]:
        """Send message using Anthropic format."""
        model = model or "claude-3-sonnet-20240229"
        
        request_data = {
            "model": model,
            "messages": [{"role": "user", "content": message}],
            "max_tokens": 150,
            "temperature": 0.7
        }
        
        start_time = time.time()
        try:
            response = await self.agent.chat_completions_create(**request_data)
            processing_time = time.time() - start_time
            
            return {
                "provider": "anthropic",
                "model": model,
                "response": response,
                "processing_time": processing_time,
                "success": True
            }
        except Exception as e:
            processing_time = time.time() - start_time
            return {
                "provider": "anthropic",
                "model": model,
                "error": str(e),
                "processing_time": processing_time,
                "success": False
            }
    
    async def _send_google_message(self, message: str, model: Optional[str] = None) -> Dict[str, Any]:
        """Send message using Google/Gemini format."""
        model = model or "gemini-1.5-pro"
        
        request_data = {
            "model": model,
            "messages": [{"role": "user", "content": message}],
            "max_tokens": 150,
            "temperature": 0.7
        }
        
        start_time = time.time()
        try:
            response = await self.agent.chat_completions_create(**request_data)
            processing_time = time.time() - start_time
            
            return {
                "provider": "google",
                "model": model,
                "response": response,
                "processing_time": processing_time,
                "success": True
            }
        except Exception as e:
            processing_time = time.time() - start_time
            return {
                "provider": "google",
                "model": model,
                "error": str(e),
                "processing_time": processing_time,
                "success": False
            }
    
    def get_supported_providers(self) -> List[str]:
        """Get list of supported providers."""
        return [provider.value for provider in ProviderType]
    
    def health_check(self) -> Dict[str, Any]:
        """Check if the client is healthy and ready to use."""
        return {
            "status": "healthy" if self.agent else "unhealthy",
            "agent_initialized": self.agent is not None,
            "supported_providers": self.get_supported_providers(),
            "timestamp": time.time()
        }


# Convenience functions for backward compatibility
async def test_openai_api(message: str = "Hello! Please respond with just 'Hi there!'", 
                         model: str = "gpt-3.5-turbo") -> Dict[str, Any]:
    """Test OpenAI API with a simple message."""
    client = UnifiedClient()
    return await client.send_message(message, ProviderType.OPENAI, model)


async def test_anthropic_api(message: str = "Hello! Please respond with just 'Hi there!'", 
                            model: str = "claude-3-sonnet-20240229") -> Dict[str, Any]:
    """Test Anthropic API with a simple message."""
    client = UnifiedClient()
    return await client.send_message(message, ProviderType.ANTHROPIC, model)


async def test_google_api(message: str = "Hello! Please respond with just 'Hi there!'", 
                         model: str = "gemini-1.5-pro") -> Dict[str, Any]:
    """Test Google API with a simple message."""
    client = UnifiedClient()
    return await client.send_message(message, ProviderType.GOOGLE, model)


if __name__ == "__main__":
    # Simple test when run directly
    async def main():
        client = UnifiedClient()
        print("Health check:", client.health_check())
        
        # Test all providers
        test_message = "Hello! Please respond with just 'Hi there!'"
        
        print("\nTesting OpenAI...")
        result = await client.send_message(test_message, ProviderType.OPENAI)
        print(f"OpenAI result: {result}")
        
        print("\nTesting Anthropic...")
        result = await client.send_message(test_message, ProviderType.ANTHROPIC)
        print(f"Anthropic result: {result}")
        
        print("\nTesting Google...")
        result = await client.send_message(test_message, ProviderType.GOOGLE)
        print(f"Google result: {result}")
    
    asyncio.run(main())
